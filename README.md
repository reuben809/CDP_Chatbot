# CDP Support Agent

## ğŸ“Œ Overview
CDP Support Agent is a web scraping and AI-powered query system that extracts, processes, and retrieves documentation from multiple **Customer Data Platforms (CDPs)**, including **Lytics, mParticle, Segment, and Zeotap**. It enables users to search and retrieve relevant documentation efficiently by leveraging Google's **Gemini AI**.

### **ğŸ”§ Key Features**
- **Web Scraping**: Automates the extraction of documentation from various CDP platforms.
- **Data Storage & Retrieval**: Stores extracted documentation and enables keyword-based search.
- **AI-Powered Query Handling**: Uses **Gemini AI** to summarize and format responses.

---

## ğŸ“‚ Project Structure
```
cdp_support_agent/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processors/        # Scraping and text processing
â”‚   â”‚   â”œâ”€â”€ lytics_scraper.py
â”‚   â”‚   â”œâ”€â”€ mparticle_scraper.py
â”‚   â”‚   â”œâ”€â”€ segment_scraper.py
â”‚   â”‚   â”œâ”€â”€ text_processor.py
â”‚   â”‚   â””â”€â”€ zeotap_scraper.py
â”‚   â”œâ”€â”€ storage/           # Storage and retrieval
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ document_store.py
â”œâ”€â”€ services/              # AI query handling
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ gemini_service.py
â”‚   â””â”€â”€ query_handler.py
â”œâ”€â”€ utils/                 # Helper functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ helper.py
â”œâ”€â”€ app.py                 # Main application entry point
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ .env                   # API keys and environment variables
```

---

## ğŸš€ Installation & Setup

### **ğŸ”¹ Prerequisites**
- Python 3.8+
- Virtual Environment (Recommended)
- ChromeDriver (if using Selenium for authentication)

### **ğŸ”¹ Clone the Repository**
```bash
git clone https://github.com/your-repo/cdp-support-agent.git
cd cdp-support-agent
```

### **ğŸ”¹ Set Up Virtual Environment (Optional)**
```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
```

### **ğŸ”¹ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **ğŸ”¹ Set Up Environment Variables**
Create a `.env` file to store API keys:
```
GEMINI_API_KEY=your_gemini_api_key
```

---

## ğŸ“Œ Usage
### **ğŸ”¹ Run the Application**
```bash
python app.py
```

### **ğŸ”¹ Scrape Documentation**
```bash
python data/processors/lytics_scraper.py
python data/processors/mparticle_scraper.py
python data/processors/segment_scraper.py
python data/processors/zeotap_scraper.py
```

### **ğŸ”¹ Query the Documentation**
```python
from services.query_handler import QueryHandler

query_handler = QueryHandler()
response = query_handler.handle_query("How do I set up user tracking in Segment?")
print(response)
```

---

## ğŸ› ï¸ Troubleshooting
**Issue:** Scraper fails to extract certain pages.
- Solution: Check if the website structure has changed. Update CSS selectors accordingly.

**Issue:** Getting 403 Forbidden errors.
- Solution: Add proper headers (User-Agent, Cookies) to avoid bot detection.

**Issue:** No response from Gemini API.
- Solution: Ensure `GEMINI_API_KEY` is correctly set in `.env`.

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

## ğŸ™Œ Contributions
Pull requests are welcome! If youâ€™d like to contribute, please open an issue first.

---

## ğŸ“© Contact
For questions, reach out via [LinkedIn](https://www.linkedin.com/in/reuben-joseph-452939291/) or email at **reuben.joseph010@icloud.com**.

